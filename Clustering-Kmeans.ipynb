{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f42a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import regex as re\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import calinski_harabasz_score, davies_bouldin_score\n",
    "import umap\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5376ceed",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect(\"wiki_articles_diseases.db\")\n",
    "\n",
    "df= pd.read_sql_query(\"SELECT * from wiki_articles_diseases_extended\", con)\n",
    "con.close()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3560756f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_words(row):\n",
    "    # Combine both fields, protect against NaN\n",
    "    text = f\"{row['nav'] or ''}|{row['entities'] or ''}\"\n",
    "    # Split on | or #\n",
    "    words = re.split(r'\\||\\#', text)\n",
    "    # Remove single-character words like \"a.\" and lowercase\n",
    "    words = [re.sub(r'\\b[A-Za-z]\\.', '', word) for word in words]\n",
    "    words = [re.sub(r'[\\xa0\\u200b\\u202f]', ' ', word) for word in words]\n",
    "    return [w.lower().strip() for w in words if len(w.strip()) > 1 and w not in STOP_WORDS]\n",
    "\n",
    "# Apply the function row-wise to create a list per row\n",
    "df['voc'] = df.apply(filter_words, axis=1)\n",
    "df['voc'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810db7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range=(1,2),min_df=5, max_df=0.7)\n",
    "\n",
    "rejoined_docs = [' '.join(doc) for doc in df['voc']]\n",
    "\n",
    "dt = tfidf.fit_transform(rejoined_docs)\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5918c07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"n_jobs value 1 overridden to 1 by setting random_state\")\n",
    "\n",
    "\n",
    "best_score = -1\n",
    "best_params = None\n",
    "\n",
    "for n_comp in range(2,11):\n",
    "    for n_neigh in range(5,15)\n",
    "        for k in range(4,11):\n",
    "            umap_model = umap.UMAP(n_neighbors=n_neigh, n_components=n_comp, random_state=42)\n",
    "            embedding = umap_model.fit_transform(dt)\n",
    "            kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "            labels = kmeans.fit_predict(embedding)\n",
    "            score = silhouette_score(embedding, labels)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_params = (n_comp, n_neigh, k)\n",
    "print(f\"Best params: n_components={best_params[0]}, n_neighbors={best_params[1]}, k={best_params[2]} with silhouette={best_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb3d866",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_model = umap.UMAP(n_neighbors=5, n_components=9, random_state=42) # Parameters changed to match grid above\n",
    "embedding = umap_model.fit_transform(dt)\n",
    "kmeans = KMeans(n_clusters=9, random_state=42, n_init=10) # Parameters changed to match grid above\n",
    "labels = kmeans.fit_predict(embedding)\n",
    "\n",
    "sizes = []\n",
    "for i in range(9):\n",
    "    sizes.append({\"cluster\": i,\n",
    "                  \"size\" : np.sum(kmeans.labels_==i)})\n",
    "    \n",
    "\n",
    "\n",
    "print(silhouette_score(embedding, labels))\n",
    "pd.DataFrame(sizes).set_index(\"cluster\").plot.bar(figsize=(16,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb33a594",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Embeddings\n",
    "#np.save(\"umap_embeddings.npy\", embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b5306e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cluster'] = kmeans.labels_\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5b6f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2D Projection\n",
    "cmap = cm.get_cmap('tab20', 9)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], c=df['cluster'], cmap=cmap)\n",
    "plt.title(\"2D Projection of Clusters\")\n",
    "plt.xlabel(\"UMAP-1\")\n",
    "plt.ylabel(\"UMAP-2\")\n",
    "plt.colorbar(label=\"Cluster\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e27ec7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_samples\n",
    "s_scores = silhouette_samples(embedding, df['cluster'])\n",
    "df['silhouette_score'] = s_scores\n",
    "df.groupby('cluster')['silhouette_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff98075d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['cluster'] == 1]['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4473ac0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"voc\"] = df[\"voc\"].apply(lambda x: \"|\".join(x))\n",
    "df['voc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db32269",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Clustered Documents\n",
    "sql = sqlite3.connect(\"clustered_diseases.db\")\n",
    "df.to_sql(\"clustered_diseases\", sql, if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8344edb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, vstack\n",
    "\n",
    "cluster_centroids = {}\n",
    "\n",
    "# Clusters 0-N\n",
    "for cluster_id in df['cluster'].unique():\n",
    "    \n",
    "    # Get all docs in the cluster\n",
    "    cluster_indices = df.index[df['cluster'] == cluster_id].tolist()\n",
    "    \n",
    "    # Get vectors of docs in cluster\n",
    "    cluster_vectors = dt[cluster_indices]\n",
    "    \n",
    "    # Get mean TF-IDF of docs in cluster\n",
    "    cluster_mean = csr_matrix(cluster_vectors.mean(axis=0))\n",
    "    \n",
    "    # Store in Dictionary\n",
    "    cluster_centroids[cluster_id] = cluster_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6515695",
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid_matrix = vstack([cluster_centroids[cid] for cid in sorted(cluster_centroids)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792a01a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Cluster Centroids\n",
    "from scipy.sparse import save_npz\n",
    "\n",
    "save_npz(\"cluster_centroids.npz\", centroid_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0a606c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat voc back to a list\n",
    "df['voc'] = df.apply(filter_words, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c874b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib_filename = 'fitted_tfidf_vectorizer.joblib'\n",
    "joblib.dump(dt, joblib_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb243973",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib_umap_filename = 'fitted_umap_model.joblib'\n",
    "joblib.dump(umap_model, joblib_umap_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
